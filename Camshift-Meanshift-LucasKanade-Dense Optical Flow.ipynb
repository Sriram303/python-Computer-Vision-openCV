{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### camshift object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# take first frame of the video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# setup default location of window\n",
    "r, h, c, w = 240, 100, 400, 160 \n",
    "track_window = (c, r, w, h)\n",
    "\n",
    "# Crop region of interest for tracking\n",
    "roi = frame[r:r+h, c:c+w]\n",
    "\n",
    "# Convert cropped window to HSV color space\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Create a mask between the HSV bounds\n",
    "lower_purple = np.array([130,60,60])\n",
    "upper_purple = np.array([175,255,255])\n",
    "mask = cv2.inRange(hsv_roi, lower_purple, upper_purple)\n",
    "\n",
    "# Obtain the color histogram of the ROI\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0,180])\n",
    "\n",
    "# Normalize values to lie between the range 0, 255\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria\n",
    "# We stop calculating the centroid shift after ten iterations \n",
    "# or if the centroid has moved at least 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read webcam frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Convert to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Calculate the histogram back projection \n",
    "        # Each pixel's value is it's probability\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "\n",
    "        # apply Camshift to get the new location\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw it on image \n",
    "        # We use polylines to represent Adaptive box \n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img2 = cv2.polylines(frame,[pts],True, 255,2)\n",
    "        \n",
    "        cv2.imshow('Camshift Tracking', img2)\n",
    "        \n",
    "        if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meanshift object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# take first frame of the video\n",
    "ret, frame = cap.read()\n",
    "print(type(frame))\n",
    "\n",
    "# setup default location of window\n",
    "r, h, c, w = 240, 100, 400, 160 \n",
    "track_window = (c, r, w, h)\n",
    "\n",
    "# Crop region of interest for tracking\n",
    "roi = frame[r:r+h, c:c+w]\n",
    "\n",
    "# Convert cropped window to HSV color space\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Create a mask between the HSV bounds\n",
    "lower_purple = np.array([125,0,0])\n",
    "upper_purple = np.array([175,255,255])\n",
    "mask = cv2.inRange(hsv_roi, lower_purple, upper_purple)\n",
    "\n",
    "# Obtain the color histogram of the ROI\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0,180])\n",
    "\n",
    "# Normalize values to lie between the range 0, 255\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria\n",
    "# We stop calculating the centroid shift after ten iterations \n",
    "# or if the centroid has moved at least 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read webcam frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        \n",
    "        # Convert to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Calculate the histogram back projection \n",
    "        # Each pixel's value is it's probability\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "\n",
    "        # apply meanshift to get the new location\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw it on image\n",
    "        x, y, w, h = track_window\n",
    "        img2 = cv2.rectangle(frame, (x,y), (x+w, y+h), 255, 2)    \n",
    "\n",
    "        cv2.imshow('Meansift Tracking', img2)\n",
    "        \n",
    "        if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load video stream\n",
    "cap = cv2.VideoCapture('C:/Users/vasukisriram/Downloads/OpenCV4/images/walking.avi')\n",
    "\n",
    "# Set parameters for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Set parameters for lucas kanade optical flow\n",
    "lucas_kanade_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "# Used to create our trails for object movement in the image \n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find inital corner locations\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    new_corners, status, errors = cv2.calcOpticalFlowPyrLK(prev_gray, \n",
    "                                                           frame_gray, \n",
    "                                                           prev_corners, \n",
    "                                                           None, \n",
    "                                                           **lucas_kanade_params)\n",
    "\n",
    "    # Select and store good points\n",
    "    good_new = new_corners[status==1]\n",
    "    good_old = prev_corners[status==1]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a,b), 5, color[i].tolist(),-1)\n",
    "        \n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    # Show Optical Flow\n",
    "    cv2.imshow('Optical Flow - Lucas-Kanade',img)\n",
    "    if cv2.waitKey(1) == ord('q'): #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prev_corners = good_new.reshape(-1,1,2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load video stream\n",
    "cap = cv2.VideoCapture('C:/Users/vasukisriram/Downloads/OpenCV4/images/walking.avi')\n",
    "\n",
    "# Get first frame\n",
    "ret, first_frame = cap.read()\n",
    "previous_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(first_frame)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read of video file\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Computes the dense optical flow using the Gunnar Farnebackâ€™s algorithm\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_gray, next, \n",
    "                                        None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # use flow to calculate the magnitude (speed) and angle of motion\n",
    "    # use these values to calculate the color to reflect speed and angle\n",
    "    magnitude, angle = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = angle * (180 / (np.pi/2))\n",
    "    hsv[...,2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    final = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Show our demo of Dense Optical Flow\n",
    "    cv2.imshow('Dense Optical Flow', final)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "    \n",
    "    # Store current image as previous image\n",
    "    previous_gray = next\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
